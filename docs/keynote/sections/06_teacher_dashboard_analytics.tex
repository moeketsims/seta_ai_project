\section{Teacher-Facing Analytics: Interpretable, Timely, and Actionable}

Teachers are the principal audience for weekly analytics. The teacher dashboard is designed to answer three questions every week: What should I teach differently? Which learners need what kind of support? How will I know if it worked? The answer is organized into a small set of views that privilege clarity over complexity.

\subsection{Overview: Risk, Mastery, and Workload}

The overview page presents: (1) current distribution of learners by status (on track, needs support, at risk), (2) a 12-week performance trend line for the class, and (3) a ``workload'' snapshot indicating how many suggested small-group sessions and one-on-one check-ins are queued. Each of these elements is linked to the reasoning behind it: which skills and misconceptions contribute to the status, and how the recommended session would address them.

\subsection{Misconception Dashboard and Deep Dives}

The \emph{Misconception Dashboard} lists the top misconception clusters by prevalence and shows their week-over-week movement. Clicking into a cluster opens a \emph{Diagnostic Deep Dive}: a narrative page with representative learner responses (de-identified), the representations best suited to address the misconception, and a short set of teacher moves for the next lesson. The aim is to minimize the distance between insight and instruction: within a few minutes, a teacher can assemble a 20-minute representation-rich mini-lesson targeted to the class's current needs.

\subsection{Skill Heatmaps and Progress Maps}

Two complementary views support planning and feedback. A \emph{Skill Heatmap} shows mastery levels across a subset of key skills for each learner, enabling grouping decisions that vary across weeks. A \emph{Skill Progression Map} shows how conceptual neighborhoods are strengthening over time, reinforcing the idea that mathematical understanding is a network of relationships, not a checklist. Teachers can annotate these views, leaving notes about what worked in class and which representations were most effective.

\subsection{Intervention Effectiveness}

The system tracks the relationship between interventions and subsequent outcomes. The \emph{Intervention Effectiveness} view displays changes in mastery on targeted skills, changes in error patterns, and movement in overall risk categories following small-group sessions, tutoring, or advisor outreach. The intent is not to ``prove'' a causal effect in the strictest sense during weekly operations, but to give reasonable, proximate evidence that a given action is helping. For more formal evaluation, the IR playbook (Section~\ref{sec:evidence}) provides study designs and metrics.

\subsection{A Rhythm of Practice}

These analytics support a weekly rhythm: diagnose on Friday, plan on the weekend or Monday morning, teach targeted representations early in the week, offer group and individual support mid-week, and reflect on Thursday. By keeping the cycle short and the views simple, the platform respects teacher time while steadily raising the precision of instruction.

